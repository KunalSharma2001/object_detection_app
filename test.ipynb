{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c18063-e9c6-4b26-b472-9498ed1a3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-22 19:55:04.846 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\Anaconda\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "\n",
    "weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "categories = weights.meta[\"categories\"] ## ['__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stopsign',]\n",
    "img_preprocess = weights.transforms() ## Scales values from 0-255 range to 0-1 range.\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model = fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.5)\n",
    "    model.eval(); ## Setting Model for Evaluation/Prediction   \n",
    "    return model\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "def make_prediction(img): \n",
    "    img_processed = img_preprocess(img) ## (3,500,500) \n",
    "    prediction = model(img_processed.unsqueeze(0)) # (1,3,500,500)\n",
    "    prediction = prediction[0]                       ## Dictionary with keys \"boxes\", \"labels\", \"scores\".\n",
    "    prediction[\"labels\"] = [categories[label] for label in prediction[\"labels\"]]\n",
    "    return prediction\n",
    "\n",
    "def create_image_with_bboxes(img, prediction): ## Adds Bounding Boxes around original Image.\n",
    "    img_tensor = torch.tensor(img) ## Transpose\n",
    "    img_with_bboxes = draw_bounding_boxes(img_tensor, boxes=prediction[\"boxes\"], labels=prediction[\"labels\"],\n",
    "                                          colors=[\"red\" if label==\"person\" else \"green\" for label in prediction[\"labels\"]] , width=2)\n",
    "    img_with_bboxes_np = img_with_bboxes.detach().numpy().transpose(1,2,0) ### (3,W,H) -> (W,H,3), Channel first to channel last.\n",
    "    return img_with_bboxes_np\n",
    "\n",
    "## Dashboard\n",
    "st.title(\"Object Detector :tea: :coffee:\")\n",
    "upload = st.file_uploader(label=\"Upload Image Here:\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "\n",
    "if upload:\n",
    "    img = Image.open(upload)\n",
    "\n",
    "    prediction = make_prediction(img) ## Dictionary\n",
    "    img_with_bbox = create_image_with_bboxes(np.array(img).transpose(2,0,1), prediction) ## (W,H,3) -> (3,W,H)\n",
    "\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.imshow(img_with_bbox)\n",
    "    plt.xticks([],[])\n",
    "    plt.yticks([],[])\n",
    "    ax.spines[[\"top\", \"bottom\", \"right\", \"left\"]].set_visible(False)\n",
    "\n",
    "    st.pyplot(fig, use_container_width=True)\n",
    "\n",
    "    del prediction[\"boxes\"]\n",
    "    st.header(\"Predicted Probabilities\")\n",
    "    st.write(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d1a322-d6a6-4de4-9f10-89ca41be25d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1635777805.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    streamlit run file.py\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8f9dc-56cc-45a8-b1bb-b5f6e8bce02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598957d5-21e9-45cd-9e5b-78e28ddead98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
